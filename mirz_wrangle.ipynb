{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707520d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "\n",
    "import env as e\n",
    "\n",
    "\n",
    "#def get_db_url(database):\n",
    "#    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "\"\"\"\n",
    "USAGE: \n",
    "Use `from wrangle import wrangle_zillow` at the top of your notebook.\n",
    "This \n",
    "\"\"\"\n",
    "\n",
    "def get_new_zillow_data():\n",
    "    \"\"\"Returns a dataframe of all 2017 properties that are Single Family Residential\"\"\"\n",
    "\n",
    "    sql = \"\"\"\n",
    "    select \n",
    "    bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, fips\n",
    "    from properties_2017\n",
    "    join propertylandusetype using (propertylandusetypeid)\n",
    "    where propertylandusedesc = \"Single Family Residential\"\n",
    "    \"\"\"\n",
    "    return pd.read_sql(sql, e.get_db_url(\"zillow\"))\n",
    "\n",
    "\n",
    "def handle_nulls(df):    \n",
    "    # We keep 99.41% of the data after dropping nulls\n",
    "    # round(df.dropna().shape[0] / df.shape[0], 4) returned .9941\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_types(df):\n",
    "    # Convert some columns to integers\n",
    "    # fips, yearbuilt, and bedrooms can be integers\n",
    "    df[\"fips\"] = df[\"fips\"].astype(str)\n",
    "    df[\"yearbuilt\"] = df[\"yearbuilt\"].astype(int)\n",
    "    df[\"bedroomcnt\"] = df[\"bedroomcnt\"].astype(int)    \n",
    "    df[\"taxvaluedollarcnt\"] = df[\"taxvaluedollarcnt\"].astype(int)\n",
    "    df[\"calculatedfinishedsquarefeet\"] = df[\"calculatedfinishedsquarefeet\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_outliers(df):\n",
    "    \"\"\"Manually handle outliers that do not represent properties likely for 99% of buyers and zillow visitors\"\"\"\n",
    "    df = df[df.bathroomcnt <= 6]\n",
    "    \n",
    "    df = df[df.bedroomcnt <= 6]\n",
    "\n",
    "    df = df[df.taxvaluedollarcnt < 2_000_000]\n",
    "\n",
    "    df = df[df.calculatedfinishedsquarefeet < 10000]\n",
    "\n",
    "    return df\n",
    "\n",
    "def rename_cols(df):\n",
    "    df = df.rename(columns={'bedroomcnt':'bedrooms', \n",
    "                            'bathroomcnt':'bathrooms', \n",
    "                            'calculatedfinishedsquarefeet':'sq_feet', \n",
    "                            'taxvaluedollarcnt':'tax_value',\n",
    "                            'yearbuilt':'year_built',\n",
    "                            'taxamount':'tax_amount'})\n",
    "    return df\n",
    "\n",
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['bedrooms', 'bathrooms', 'tax_amount', 'sq_feet'],\n",
    "               return_scaler=False):\n",
    "    '''\n",
    "    Scales the 3 data splits. \n",
    "    Takes in train, validate, and test data splits and returns their scaled counterparts.\n",
    "    If return_scalar is True, the scaler object will be returned as well\n",
    "    '''\n",
    "    # make copies of our original data so we dont gronk up anything\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    #     make the thing\n",
    "    scaler = MinMaxScaler()\n",
    "    #     fit the thing\n",
    "    scaler.fit(train[columns_to_scale])\n",
    "    # applying the scaler:\n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(validate[columns_to_scale]),\n",
    "                                                  columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    if return_scaler:\n",
    "        return scaler, train_scaled, validate_scaled, test_scaled\n",
    "    else:\n",
    "        return train_scaled, validate_scaled, test_scaled\n",
    "\n",
    "def split_data(df):\n",
    "    '''\n",
    "    take in a DataFrame and return train, validate, and test DataFrames.\n",
    "    return train, validate, test DataFrames.\n",
    "    '''\n",
    "    \n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "    \n",
    "    train, validate = train_test_split(train_validate, \n",
    "                                       test_size=.3, \n",
    "                                       random_state=123)\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "def clean_zillow(df):\n",
    "    df = handle_nulls(df)\n",
    "\n",
    "    df = optimize_types(df)\n",
    "\n",
    "    df = handle_outliers(df)\n",
    "\n",
    "    df = rename_cols(df)\n",
    "\n",
    "    df.to_csv(\"zillow.csv\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def wrangle_zillow():\n",
    "    \"\"\"\n",
    "    Acquires Zillow data\n",
    "    Handles nulls\n",
    "    optimizes or fixes data types\n",
    "    handles outliers w/ manual logic\n",
    "    returns a clean dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    filename = \"zillow.csv\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = get_new_zillow_data()\n",
    "\n",
    "        df = clean_zillow(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f639e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
